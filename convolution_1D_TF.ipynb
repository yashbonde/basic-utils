{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution in 1D\n",
    "\n",
    "Simple Implementation of convolution in 1D.\n",
    "\n",
    "Convolution in one dimension works as follows.\n",
    "\n",
    "![alt_text](https://qph.ec.quoracdn.net/main-qimg-523434af0d21bb0b59454aa9563cc90b-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a toy data\n",
    "\n",
    "We create a simple sequential data, where sequence length is 200 and each value ranges between [-1000, 1000].\n",
    "\n",
    "The output has three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# toy data params\n",
    "seq_len = 200 # length of training sequence\n",
    "examples = 100 # number of examples\n",
    "val_high = 1000 # maximum value in the sequence\n",
    "val_low = -1000 # minimum value in sequence\n",
    "# we select this type of max-min values because we often find sequential data to be\n",
    "# extremely sparse and-or of large fluctuations in values\n",
    "n_classes = 3 # number of classes in output\n",
    "\n",
    "# hyper params\n",
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Shape of input data: (200, 1)\n",
      "[*]Shape of output data: (3,)\n"
     ]
    }
   ],
   "source": [
    "# making input data\n",
    "data_x = np.random.randint(high = val_high, low = val_low, size = (examples, seq_len, 1))\n",
    "print('[*]Shape of input data:', data_x.shape[1:])\n",
    "\n",
    "# making output data\n",
    "# making output data\n",
    "data_y = np.zeros(shape = (examples, n_classes))\n",
    "for i in range(len(data_y)):\n",
    "    data_y[i][np.random.randint(n_classes)] = 1.0\n",
    "print('[*]Shape of output data:', data_y.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the model\n",
    "\n",
    "Input --> Convolution_Layer --> Dense_Layer --> Output --> Loss <-- Actual_Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the placeholders\n",
    "x = tf.placeholder(tf.float32, shape = [None, seq_len, 1], name = 'x')\n",
    "y = tf.placeholder(tf.float32, shape = [None, n_classes], name = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For convolution API given\n",
    "tf.nn.conv1d(input, filter, strides, padding, ...)\n",
    "input = input to the convolution layer --> should be a 3D tensor [batch_size, in_width, in_channels]\n",
    "filter = weights to the convolution layer --> should be a 3D tensor\n",
    "strides = An integer defining by how much the filter should move\n",
    "padding = \"SAME\" or \"VALID\"\n",
    "'''\n",
    "\n",
    "# Defining the weights a.k.a. filter\n",
    "# it is of shape --> [sliding_window_size, in_channels, out_channels]\n",
    "W_conv = tf.Variable(tf.truncated_normal([20, 1, 10]), name = 'W_conv')\n",
    "# defining bias\n",
    "b_conv = tf.Variable(tf.truncated_normal([10]), name = 'b_conv')\n",
    "# doing the convolution\n",
    "h_conv = tf.nn.conv1d(x, W_conv, stride = 5, padding = 'SAME') + b_conv\n",
    "# the output of the conv1d is [?, seq_len/stride, out_channel]\n",
    "\n",
    "# Dense Layer\n",
    "W_dense = tf.Variable(tf.truncated_normal([40*10, n_classes]), name = 'W_dense')\n",
    "b_dense = tf.Variable(tf.truncated_normal([n_classes]), name = 'W_dense')\n",
    "# flattening the output of convolution layer\n",
    "h_conv_flat = tf.reshape(h_conv, [-1, 40*10])\n",
    "y_ = tf.matmul(h_conv_flat, W_dense) + b_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determining the loss function and accuracy function\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = y_)\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, accuracy : 0.38999998569488525\n",
      "Epoch 40, accuracy : 0.38999998569488525\n",
      "Epoch 60, accuracy : 0.46000000834465027\n",
      "Epoch 80, accuracy : 0.46000000834465027\n",
      "Epoch 100, accuracy : 0.5\n",
      "Epoch 120, accuracy : 0.550000011920929\n",
      "Epoch 140, accuracy : 0.5899999737739563\n",
      "Epoch 160, accuracy : 0.6399999856948853\n",
      "Epoch 180, accuracy : 0.6899999976158142\n",
      "Epoch 200, accuracy : 0.6700000166893005\n"
     ]
    }
   ],
   "source": [
    "# Now we train the model\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    feed_dict = {x: data_x, y: data_y}\n",
    "    _, = sess.run([train_step], feed_dict = feed_dict)\n",
    "    if (e+1) % 20 == 0:\n",
    "        acc = sess.run([accuracy], feed_dict = feed_dict)\n",
    "        print('Epoch {0}, accuracy : {1}'.format(e+1, acc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the accuracy increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
